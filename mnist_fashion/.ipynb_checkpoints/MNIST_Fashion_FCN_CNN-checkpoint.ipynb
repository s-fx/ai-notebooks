{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce6e02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y = train_data[0]\n",
    "x_ = x.reshape(28,28,1)\n",
    "plt.imshow(x_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "def train_loader(batch_size):\n",
    "    return DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "def test_loader(batch_size):\n",
    "    return DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca26eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define FCN model \n",
    "class FashionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionNN, self).__init__()\n",
    "        self.input = nn.Sequential(\n",
    "                            nn.Flatten(),\n",
    "                            nn.Linear(28*28, 512),\n",
    "                            nn.ReLU())\n",
    "        self.hidden = nn.Sequential(\n",
    "                            nn.Linear(512,128),\n",
    "                            nn.ReLU())\n",
    "        self.output = nn.Sequential(\n",
    "                            nn.Linear(128,10))\n",
    "     \n",
    "    def forward(self,x):\n",
    "        x = self.input(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters_detail(model):\n",
    "    total_params = 0\n",
    "    print('Modules: Parameters')\n",
    "    print('-------------------')\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        print(name,': ',param)\n",
    "        total_params+=param\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "    # generall dtype is float32 = 32 bits = 4 bytes \n",
    "    print(f\"Disk space neede with float32: {total_params*4/1e6} mb\")\n",
    "    \n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(model, dataloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            out = model(images)\n",
    "            \n",
    "            preds = np.argmax(out.detach().cpu().numpy(), axis=1)\n",
    "            labels = labels.cpu().numpy()\n",
    "        \n",
    "            correct += np.sum(preds == labels)\n",
    "            total += len(preds)\n",
    "\n",
    "    \n",
    "    acc = correct/total * 100\n",
    "    print('Accuracy :', round(acc,3), \"%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df53d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FashionNN().to(device)\n",
    "print(f\"Model architecture FCN: {model} \\n\")\n",
    "print(count_parameters_detail(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "epochs = []\n",
    "losses, test_accuracies, train_accuracies = [], [], []\n",
    "\n",
    "for epoch in range(1,10):\n",
    "    epochs.append(epoch)\n",
    "    batch = 128\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for data, labels in train_loader(batch):\n",
    "        \n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out,labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    losses.append(running_loss)\n",
    "    train_acc_ = test_acc(model=model, dataloader=train_loader(128), device=device)\n",
    "    test_acc_ = test_acc(model=model, dataloader=test_loader(128), device=device)\n",
    "    test_accuracies.append(test_acc_)\n",
    "    train_accuracies.append(train_acc_)\n",
    "    print('Final Test Accuracy:',test_acc_,'%')\n",
    "    print(\"Final Train Accuracy:\", train_acc_, '%')\n",
    "    print('Last Train Loss:', running_loss)\n",
    "    print()\n",
    "    #plt.plot(epochs, t_loss, '--o')\n",
    "    \n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.plot(test_accuracies)\n",
    "plt.plot(train_accuracies)\n",
    "#plt.grid()\n",
    "#plt.legend()\n",
    "#plt.xlabel('Epochs', size=14)\n",
    "#plt.ylabel('Loss', size=14)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eaa2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image = torch.rand((28,28), requires_grad=True).unsqueeze(0).unsqueeze(0)\n",
    "class_label = torch.ones(1,dtype=torch.long)*0\n",
    "\n",
    "image = random_image[0,0].detach().numpy()\n",
    "plt.imshow(image, cmap=\"gray\",interpolation=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c04a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(1,10000):\n",
    "    \n",
    "    \n",
    "    random_image, class_label = random_image.to(device), class_label.to(device)\n",
    "    \n",
    "    out = model(random_image)\n",
    "    \n",
    "    loss = criterion(out, class_label)\n",
    "  \n",
    "    random_image_grad = torch.autograd.grad(loss,random_image)\n",
    "    \n",
    "    random_image = random_image - 0.1*random_image_grad[0]\n",
    "    \n",
    "    if (epoch%1000==0):\n",
    "        print(\"Epoch\",epoch)\n",
    "        print('Loss:',loss)\n",
    "        \n",
    "        image = random_image[0,0].detach().numpy()\n",
    "        plt.imshow(image, cmap=\"gray\",interpolation=\"none\")\n",
    "        plt.show()\n",
    "        \n",
    "        print('Preds:',np.argmax(out.detach().cpu().numpy(), axis=1))\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e02a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import pandas as pd\n",
    "import json \n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "import torchvision\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Network,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,4,kernel_size=3,stride=1,padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(4,8,kernel_size=3,stride=1,padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(200,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        \n",
    "    def forward(self,x,test=False):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = nn.Flatten()(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    lr = [.01, .001],\n",
    "    batch_size = [64, 128, 256],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2011cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = RunBuilder.get_runs(params)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b512cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class, help track loss, accuracy, epoch time, run time, \n",
    "# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n",
    "class RunManager():\n",
    "  def __init__(self):\n",
    "\n",
    "    # tracking every epoch count, loss, accuracy, time\n",
    "    self.epoch_count = 0\n",
    "    self.epoch_loss = 0\n",
    "    self.epoch_num_correct = 0\n",
    "    self.epoch_start_time = None\n",
    "\n",
    "    # tracking every run count, run data, hyper-params used, time\n",
    "    self.run_params = None\n",
    "    self.run_count = 0\n",
    "    self.run_data = []\n",
    "    self.run_start_time = None\n",
    "\n",
    "    # record model, loader and TensorBoard \n",
    "    self.network = None\n",
    "    self.loader = None\n",
    "    self.tb = None\n",
    "\n",
    "  # record the count, hyper-param, model, loader of each run\n",
    "  # record sample images and network graph to TensorBoard  \n",
    "  def begin_run(self, run, network, loader):\n",
    "\n",
    "    self.run_start_time = time.time()\n",
    "\n",
    "    self.run_params = run\n",
    "    self.run_count += 1\n",
    "\n",
    "    self.network = network\n",
    "    self.loader = loader\n",
    "    self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "    images, labels = next(iter(self.loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    self.tb.add_image('images', grid)\n",
    "    self.tb.add_graph(self.network, images)\n",
    "\n",
    "  # when run ends, close TensorBoard, zero epoch count\n",
    "  def end_run(self):\n",
    "    self.tb.close()\n",
    "    self.epoch_count = 0\n",
    "\n",
    "  # zero epoch count, loss, accuracy, \n",
    "  def begin_epoch(self):\n",
    "    self.epoch_start_time = time.time()\n",
    "\n",
    "    self.epoch_count += 1\n",
    "    self.epoch_loss = 0\n",
    "    self.epoch_num_correct = 0\n",
    "\n",
    "  # \n",
    "  def end_epoch(self):\n",
    "    # calculate epoch duration and run duration(accumulate)\n",
    "    epoch_duration = time.time() - self.epoch_start_time\n",
    "    run_duration = time.time() - self.run_start_time\n",
    "\n",
    "    # record epoch loss and accuracy\n",
    "    loss = self.epoch_loss / len(self.loader.dataset)\n",
    "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "    # Record epoch loss and accuracy to TensorBoard \n",
    "    self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "    # Record params to TensorBoard\n",
    "    for name, param in self.network.named_parameters():\n",
    "      self.tb.add_histogram(name, param, self.epoch_count)\n",
    "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "    \n",
    "    # Write into 'results' (OrderedDict) for all run related data\n",
    "    results = OrderedDict()\n",
    "    results[\"run\"] = self.run_count\n",
    "    results[\"epoch\"] = self.epoch_count\n",
    "    results[\"loss\"] = loss\n",
    "    results[\"accuracy\"] = accuracy\n",
    "    results[\"epoch duration\"] = epoch_duration\n",
    "    results[\"run duration\"] = run_duration\n",
    "\n",
    "    # Record hyper-params into 'results'\n",
    "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "    self.run_data.append(results)\n",
    "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
    "\n",
    "    # display epoch information and show progress\n",
    "    clear_output(wait=True)\n",
    "    display(df)\n",
    "\n",
    "  # accumulate loss of batch into entire epoch loss\n",
    "  def track_loss(self, loss):\n",
    "    # multiply batch size so variety of batch sizes can be compared\n",
    "    self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "  # accumulate number of corrects of batch into entire epoch num_correct\n",
    "  def track_num_correct(self, preds, labels):\n",
    "    self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def _get_num_correct(self, preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "  \n",
    "  # save end results of all runs into csv, json for further analysis\n",
    "  def save(self, fileName):\n",
    "\n",
    "    pd.DataFrame.from_dict(\n",
    "        self.run_data, \n",
    "        orient = 'columns',\n",
    "    ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_manager = RunManager()\n",
    "\n",
    "# get all runs from params using RunBuilder class\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    # if params changes, following line of code should reflect the changes too\n",
    "    network = CNN_Network()\n",
    "    loader = train_loader(run.batch_size)\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    run_manager.begin_run(run, network, loader)\n",
    "    for epoch in range(epochs):\n",
    "      \n",
    "      run_manager.begin_epoch()\n",
    "      for batch in loader:\n",
    "        \n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run_manager.track_loss(loss)\n",
    "        run_manager.track_num_correct(preds, labels)\n",
    "\n",
    "      run_manager.end_epoch()\n",
    "    run_manager.end_run()\n",
    "\n",
    "# when all runs are done, save results to files\n",
    "run_manager.save('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d6a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
